apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu
spec:
  # Template for GPU nodes
  template:
    metadata:
      labels:
        cni: cilium
        node-type: gpu
        workload-class: ml-training
        nvidia.com/gpu.present: "true"

    spec:
      # Reference to GPU EC2NodeClass
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: gpu

      # GPU instance requirements
      requirements:
        # Architecture - GPU instances are x86_64
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]

        # Capacity type - GPU workloads can use spot for training
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand", "spot"]

        # Specific GPU instance types
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            # G5 instances - NVIDIA A10G GPU (cost-effective)
            - "g5.xlarge"      # 1x A10G, 4 vCPU, 16 GiB
            - "g5.2xlarge"     # 1x A10G, 8 vCPU, 32 GiB
            - "g5.4xlarge"     # 1x A10G, 16 vCPU, 64 GiB
            - "g5.8xlarge"     # 1x A10G, 32 vCPU, 128 GiB
            - "g5.12xlarge"    # 4x A10G, 48 vCPU, 192 GiB
            - "g5.16xlarge"    # 1x A10G, 64 vCPU, 256 GiB
            - "g5.24xlarge"    # 4x A10G, 96 vCPU, 384 GiB
            - "g5.48xlarge"    # 8x A10G, 192 vCPU, 768 GiB
            # P4d instances - NVIDIA A100 GPU (high performance)
            - "p4d.24xlarge"   # 8x A100, 96 vCPU, 1152 GiB
            # P5 instances - NVIDIA H100 GPU (cutting edge)
            - "p5.48xlarge"    # 8x H100, 192 vCPU, 2048 GiB

      # Taints to ensure only GPU workloads are scheduled
      taints:
        - key: nvidia.com/gpu
          effect: NoSchedule
          value: "true"
        - key: workload-type
          effect: NoSchedule
          value: "gpu"

      # Startup taints
      startupTaints:
        - key: node.cilium.io/agent-not-ready
          effect: NoExecute
          value: "true"

  # Resource limits for GPU pool
  limits:
    cpu: "500"
    memory: 2000Gi
    nvidia.com/gpu: "100"

  # Weight - higher priority than general pool
  weight: 100

  # Disruption controls - more conservative for GPU workloads
  disruption:
    # Only consolidate when empty (training jobs are expensive to interrupt)
    consolidationPolicy: WhenEmpty

    # Wait longer before consolidating
    consolidateAfter: 30m

    # Disruption budgets
    budgets:
      - nodes: "0"  # No automatic disruptions for GPU nodes
